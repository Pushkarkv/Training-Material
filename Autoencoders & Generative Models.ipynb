{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abfab9b7",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416b3f0",
   "metadata": {},
   "source": [
    "An autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data (unsupervised learning). The encoding is validated and refined by attempting to regenerate the input from the encoding. The autoencoder learns a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore insignificant data (“noise”).\n",
    "\n",
    "Variants exist, aiming to force the learned representations to assume useful properties. Examples are regularized autoencoders (Sparse, Denoising and Contractive), which are effective in learning representations for subsequent classification tasks, and Variational autoencoders, with applications as generative models. Autoencoders are applied to many problems, from facial recognition, feature detection, anomaly detection to acquiring the meaning of words. Autoencoders are also generative models: they can randomly generate new data that is similar to the input data (training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a68da2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.compthree.com/images/blog/ae/ae.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"https://www.compthree.com/images/blog/ae/ae.png\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0890c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/600/1*nqzWupxC60iAH2dYrFT78Q.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/600/1*nqzWupxC60iAH2dYrFT78Q.png\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b962e4c",
   "metadata": {},
   "source": [
    "## Sparse autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9892d8c5",
   "metadata": {},
   "source": [
    "Learning representations in a way that encourages sparsity improves performance on classification tasks. Sparse autoencoders may include more (rather than fewer) hidden units than inputs, but only a small number of the hidden units are allowed to be active at the same time (thus, sparse). This constraint forces the model to respond to the unique statistical features of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37cbc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Autoencoder_sparso.png/330px-Autoencoder_sparso.png\" width=\"300\" height=\"100\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Autoencoder_sparso.png/330px-Autoencoder_sparso.png\", width=300, height=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305dde2",
   "metadata": {},
   "source": [
    "## Denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7eb9af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/724/1*qKiQ1noZdw8k05-YRIl6hw.jpeg\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/724/1*qKiQ1noZdw8k05-YRIl6hw.jpeg\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e411c2b0",
   "metadata": {},
   "source": [
    "# Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e5436",
   "metadata": {},
   "source": [
    "## Variational autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12923876",
   "metadata": {},
   "source": [
    "Variational autoencoders (VAEs) belong to the families of variational Bayesian methods. Despite the architectural similarities with basic autoencoders, VAEs are architecture with different goals and with a completely different mathematical formulation. The latent space is in this case composed by a mixture of distributions instead of a fixed vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f3e69",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d27ece",
   "metadata": {},
   "source": [
    "## GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f218444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/1400/1*TKr1dtcNgJCA8uYY1OhmSg.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/1400/1*TKr1dtcNgJCA8uYY1OhmSg.png\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70550b44",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480dcd69",
   "metadata": {},
   "source": [
    "## Loss function of GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5587c7db",
   "metadata": {},
   "source": [
    "https://developers.google.com/machine-learning/gan/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fedf5db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.machinecurve.com/wp-content/uploads/2019/10/image-5-1024x122.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://www.machinecurve.com/wp-content/uploads/2019/10/image-5-1024x122.png\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3b1bc8",
   "metadata": {},
   "source": [
    "## Style GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e925bafc",
   "metadata": {},
   "source": [
    "https://thispersondoesnotexist.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c831e6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
