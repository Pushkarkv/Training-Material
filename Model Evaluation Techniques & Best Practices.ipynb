{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bdef11f",
   "metadata": {},
   "source": [
    " # Need for Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec96431",
   "metadata": {},
   "source": [
    "Machine learning algorithm just sees number — if there is a vast difference in the range say few ranging in thousands and few ranging in the tens, and it makes the underlying assumption that higher ranging numbers have superiority of some sort. So these more significant number starts playing a more decisive role while training the model.\n",
    "\n",
    "The machine learning algorithm works on numbers and does not know what that number represents. A weight of 10 grams and a price of 10 dollars represents completely two different things — which is a no brainer for humans, but for a model as a feature, it treats both as same.\n",
    "\n",
    "So these more significant number starts playing a more decisive role while training the model. Thus feature scaling is needed to bring every feature in the same footing without any upfront importance. Interestingly, if we convert the weight to “Kg,” then “Price” becomes dominant.\n",
    "\n",
    "Another reason why feature scaling is applied is that few algorithms like Neural network gradient descent converge much faster with feature scaling than without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4aa0bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/900/1*yi0VULDJmBfb1NaEikEciA.png\" width=\"800\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"https://miro.medium.com/max/900/1*yi0VULDJmBfb1NaEikEciA.png\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5453da4d",
   "metadata": {},
   "source": [
    "Some examples of algorithms where feature scaling matters are:\n",
    "\n",
    "**K-nearest neighbors** (KNN) with a Euclidean distance measure is sensitive to magnitudes and hence should be scaled for all features to weigh in equally.\n",
    "\n",
    "**K-Means** uses the Euclidean distance measure here feature scaling matters.\n",
    "\n",
    "Scaling is critical while performing **Principal Component Analysis** (PCA). PCA tries to get the features with maximum variance, and the variance is high for high magnitude features and skews the PCA towards high magnitude features.\n",
    "\n",
    "We can speed up **gradient descent** by scaling because θ descends quickly on small ranges and slowly on large ranges, and oscillates inefficiently down to the optimum when the variables are very uneven."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a51458",
   "metadata": {},
   "source": [
    "Algorithms that do not require normalization/scaling are the ones that rely on rules. They would not be affected by any monotonic transformations of the variables. Scaling is a monotonic transformation. Examples of algorithms in this category are all the tree-based algorithms — CART, Random Forests, Gradient Boosted Decision Trees. These algorithms utilize rules (series of inequalities) and do not require normalization.\n",
    "\n",
    "Algorithms like Linear Discriminant Analysis(LDA), Naive Bayes is by design equipped to handle this and give weights to the features accordingly. Performing features scaling in these algorithms may not have much effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d596def",
   "metadata": {},
   "source": [
    "# Min Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c30adf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/344/0*Gy668nQfirqf6W4c\" width=\"300\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/344/0*Gy668nQfirqf6W4c\", width=300, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e106f7a5",
   "metadata": {},
   "source": [
    "Transform features by scaling each feature to a given range. This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g., between zero and one. This Scaler shrinks the data within the range of -1 to 1 if there are negative values. We can set the range like [0,1] or [0,5] or [-1,1].\n",
    "\n",
    "This Scaler responds well if the standard deviation is small and when a distribution is not Gaussian. This Scaler is sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e4c18",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97aebd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/257/0*P9VH6Ba9R9Az7uMX\" width=\"300\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/257/0*P9VH6Ba9R9Az7uMX\", width=300, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d105831b",
   "metadata": {},
   "source": [
    "The Standard Scaler assumes data is normally distributed within each feature and scales them such that the distribution centered around 0, with a standard deviation of 1.\n",
    "\n",
    "Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. If data is not normally distributed, this is not the best Scaler to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd5121",
   "metadata": {},
   "source": [
    "# Data Leakage in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b279c",
   "metadata": {},
   "source": [
    "Data leakage is when information from outside the training dataset is used to create the model. This additional information can allow the model to learn or know something that it otherwise would not know and in turn invalidate the estimated performance of the mode being constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a7f510",
   "metadata": {},
   "source": [
    "# Techniques To Minimize Data Leakage When Building Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc7bd85",
   "metadata": {},
   "source": [
    "# Using Validation and Test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a226b9c",
   "metadata": {},
   "source": [
    "**Training Dataset**: The actual dataset that we use to train the model (weights and biases in the case of a Neural Network). The model sees and learns from this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169951a0",
   "metadata": {},
   "source": [
    "**Validation Dataset**: This dataset is used to evaluate a given model, but this is for frequent evaluation. We, as machine learning engineers, use this data to fine-tune the model hyperparameters. Hence the model occasionally sees this data, but never does it “Learn” from this. We use the validation set results, and update higher level hyperparameters. So the validation set affects a model, but only indirectly. The validation set is also known as the Dev set or the Development set. This makes sense since this dataset helps during the “development” stage of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf6d199",
   "metadata": {},
   "source": [
    "**Test Dataset**: This dataset is the gold standard used to evaluate the model. It is only used once a model is completely trained(using the train and validation sets). The test set is generally what is used to evaluate competing models (For example on many Kaggle competitions, the validation set is released initially along with the training set and the actual test set is only released when the competition is about to close, and it is the result of the the model on the Test set that decides the winner). Many a times the validation set is used as the test set, but it is not good practice. The test set is generally well curated. It contains carefully sampled data that spans the various classes that the model would face, when used in the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb0fc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/1050/1*Nv2NNALuokZEcV6hYEHdGA.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/1050/1*Nv2NNALuokZEcV6hYEHdGA.png\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e9d58",
   "metadata": {},
   "source": [
    "# K-Fold Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea76f8ce",
   "metadata": {},
   "source": [
    "The Training Dataset is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k “folds”\n",
    "\n",
    "A model is trained using **k-1** of the folds as training data and evaluated/ validated on one of the folds.\n",
    "\n",
    "The resulting model is validated on the remaining part of the data.\n",
    "\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems such as inverse inference where the number of samples is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "817a5509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b5f65d",
   "metadata": {},
   "source": [
    "# Model Evaluation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f2752e",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6489ceb4",
   "metadata": {},
   "source": [
    "True positives (TP): Predicted positive and are actually positive.\n",
    "\n",
    "False positives (FP): Predicted positive and are actually negative.\n",
    "\n",
    "True negatives (TN): Predicted negative and are actually negative.\n",
    "\n",
    "False negatives (FN): Predicted negative and are actually positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f122b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/911/1*yYctsCAlkQHixEHYy0dHPw.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/911/1*yYctsCAlkQHixEHYy0dHPw.png\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5cb822",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53cc514",
   "metadata": {},
   "source": [
    "The most commonly used metric to judge a model and is actually not a clear indicator of the performance. The worse happens when classes are imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a4572e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/345/1*PfGgbFFjLjGYkp_lHXFvgg.png\" width=\"300\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/345/1*PfGgbFFjLjGYkp_lHXFvgg.png\", width=300, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acea9d87",
   "metadata": {},
   "source": [
    "# Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07178cc5",
   "metadata": {},
   "source": [
    "Percentage of positive instances out of the total predicted positive instances. Here denominator is the model prediction done as positive from the whole given dataset. Take it as to find out ‘how much the model is right when it says it is right’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "738bff94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/158/1*LWDZT9hRYc7BAzpeZUOZrg.png\" width=\"150\" height=\"100\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/158/1*LWDZT9hRYc7BAzpeZUOZrg.png\", width=150, height=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffd5e6f",
   "metadata": {},
   "source": [
    "# Recall/ Sensitivity/ True Positive Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1713cba",
   "metadata": {},
   "source": [
    "Percentage of positive instances out of the total actual positive instances. Therefore denominator (TP + FN) here is the actual number of positive instances present in the dataset. Take it as to find out ‘how much extra right ones, the model missed when it showed the right ones’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "008bf442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/167/1*U_CKVn3iy9WN6ckfZ9_LeA.png\" width=\"150\" height=\"100\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/167/1*U_CKVn3iy9WN6ckfZ9_LeA.png\", width=150, height=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb7feaf",
   "metadata": {},
   "source": [
    "# Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c988a7a4",
   "metadata": {},
   "source": [
    "Percentage of negative instances out of the total actual negative instances. Therefore denominator (TN + FP) here is the actual number of negative instances present in the dataset. It is similar to recall but the shift is on the negative instances. Like finding out how many healthy patients were not having cancer and were told they don’t have cancer. Kind of a measure to see how separate the classes are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b391fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/170/1*LbcyTuMKRer8sn44Hb-k2A.png\" width=\"150\" height=\"100\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/170/1*LbcyTuMKRer8sn44Hb-k2A.png\", width=150, height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aacd0b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg\" width=\"800\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg\", width=800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c806344",
   "metadata": {},
   "source": [
    "# F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a79e734",
   "metadata": {},
   "source": [
    "It is the harmonic mean of precision and recall. This takes the contribution of both, so higher the F1 score, the better. See that due to the product in the numerator if one goes low, the final F1 score goes down significantly. So a model does well in F1 score if the positive predicted are actually positives (precision) and doesn't miss out on positives and predicts them negative (recall).\n",
    "\n",
    "One drawback is that both precision and recall are given equal importance due to which according to our application we may need one higher than the other and F1 score may not be the exact metric for it. Therefore either weighted-F1 score or seeing the PR or ROC curve can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecf16ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/800/1*rxeJQS0ALoR3pFNFjgTD6g.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/800/1*rxeJQS0ALoR3pFNFjgTD6g.png\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6235fe",
   "metadata": {},
   "source": [
    "# PR curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56452bf",
   "metadata": {},
   "source": [
    "It is the curve between precision and recall for various threshold values. In the figure below we have 6 predictors showing their respective precision-recall curve for various threshold values. The top right part of the graph is the ideal space where we get high precision and recall. Based on our application we can choose the predictor and the threshold value. PR AUC is just the area under the curve. The higher its numerical value the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d156032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/26833433/76019078-0a79fb00-5ed6-11ea-8b5b-5697bbbd7e7e.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://user-images.githubusercontent.com/26833433/76019078-0a79fb00-5ed6-11ea-8b5b-5697bbbd7e7e.png\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74233b",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f397a29",
   "metadata": {},
   "source": [
    "ROC stands for receiver operating characteristic and the graph is plotted against TPR and FPR for various threshold values. As TPR increases FPR also increases. As you can see in the first figure, we have four categories and we want the threshold value that leads us closer to the top left corner. Comparing different predictors (here 3) on a given dataset also becomes easy as you can see in figure 2, one can choose the threshold according to the application at hand. ROC AUC is just the area under the curve, the higher its numerical value the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd23803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://docs.eyesopen.com/toolkits/cookbook/python/_images/fprocs2img-ACE.svg\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://docs.eyesopen.com/toolkits/cookbook/python/_images/fprocs2img-ACE.svg\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c1f5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.graphpad.com/guides/prism/latest/curve-fitting/images/hmfile_hash_9166880d.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://www.graphpad.com/guides/prism/latest/curve-fitting/images/hmfile_hash_9166880d.png\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb9cd44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
