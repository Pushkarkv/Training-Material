{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed89470",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa627f1",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Deep_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56674e9",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219931f",
   "metadata": {},
   "source": [
    "Artificial neural networks (ANNs), usually simply called neural networks (NNs), are computing systems inspired by the biological neural networks that constitute animal brains.\n",
    "\n",
    "An ANN is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal to other neurons. An artificial neuron receives a signal then processes it and can signal neurons connected to it. The \"signal\" at a connection is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs. The connections are called edges. Neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Neurons may have a threshold such that a signal is sent only if the aggregate signal crosses that threshold. Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer), to the last layer (the output layer), possibly after traversing the layers multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5880f17",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8989c8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/1068/1*Z1_IgFO1c6tq4Tz1iwJraw.png\" width=\"400\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"https://miro.medium.com/max/1068/1*Z1_IgFO1c6tq4Tz1iwJraw.png\", width=400, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1362721d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://camo.githubusercontent.com/74e8378ad0f412ad39f53e5ef4d0f1d4fa69250585cd60e97d12a4c601d82fe9/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313630302f312a71314d374c47694454697277552d344c634671375f512e706e67\" width=\"800\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://camo.githubusercontent.com/74e8378ad0f412ad39f53e5ef4d0f1d4fa69250585cd60e97d12a4c601d82fe9/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313630302f312a71314d374c47694454697277552d344c634671375f512e706e67\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d910303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://s3.ap-south-1.amazonaws.com/afteracademy-server-uploads/mastering-backpropagation-in-neural-network-basic-nn.jpg\" width=\"600\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://s3.ap-south-1.amazonaws.com/afteracademy-server-uploads/mastering-backpropagation-in-neural-network-basic-nn.jpg\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5af6867",
   "metadata": {},
   "source": [
    "https://machinelearningknowledge.ai/animated-explanation-of-feed-forward-neural-network-architecture/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec21902e",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca331c0",
   "metadata": {},
   "source": [
    "Loss functions measure how far an estimated value is from its true value. A loss function maps decisions to their associated costs. Loss functions are not fixed, they change depending on the task in hand and the goal to be met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1b624d",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f773d4",
   "metadata": {},
   "source": [
    "https://keras.io/api/losses/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377399c",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cbdeda",
   "metadata": {},
   "source": [
    "Optimizers are used to update weights and biases i.e. the internal parameters of a model to reduce the error. The most important technique and the foundation of how we train and optimize our model is using Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0c6d8b",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/optimizers-for-training-neural-network-59450d71caf6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0064f",
   "metadata": {},
   "source": [
    "https://keras.io/api/optimizers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc875e0",
   "metadata": {},
   "source": [
    " # Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6182f3",
   "metadata": {},
   "source": [
    "Evaluating your machine learning algorithm is an essential part of any project. Your model may give you satisfying results when evaluated using a metric say accuracy_score but may give poor results when evaluated against other metrics such as logarithmic_loss or any other such metric. Most of the times we use classification accuracy to measure the performance of our model, however it is not enough to truly judge our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534dbfa",
   "metadata": {},
   "source": [
    "https://keras.io/api/metrics/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea92333",
   "metadata": {},
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02f0619",
   "metadata": {},
   "source": [
    "The activation function is a non-linear transformation that we do over the input before sending it to the next layer of neurons or finalizing it as output. Several different types of activation functions are used in Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296f3977",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fac518",
   "metadata": {},
   "source": [
    "https://keras.io/api/layers/activations/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a27e5",
   "metadata": {},
   "source": [
    "# Vanishing and Exploding Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69467945",
   "metadata": {},
   "source": [
    "As the backpropagation algorithm advances downwards(or backward) from the output layer towards the input layer, the gradients often get smaller and smaller and approach zero which eventually leaves the weights of the initial or lower layers nearly unchanged. As a result, the gradient descent never converges to the optimum. This is known as the **vanishing gradients** problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30374330",
   "metadata": {},
   "source": [
    "On the contrary, in some cases, the gradients keep on getting larger and larger as the backpropagation algorithm progresses. This, in turn, causes very large weight updates and causes the gradient descent to diverge. This is known as the **exploding gradients** problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdbbd25",
   "metadata": {},
   "source": [
    "# Weight Initialization Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745d35b",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/weight-initialization-techniques-in-neural-networks-26c649eb3b78"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b376a8",
   "metadata": {},
   "source": [
    "https://keras.io/api/layers/initializers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b21ace",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea57d01",
   "metadata": {},
   "source": [
    "Regularizers allow you to apply penalties on layer parameters or layer activity during optimization. These penalties are summed into the loss function that the network optimizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db747239",
   "metadata": {},
   "source": [
    "https://keras.io/api/layers/regularizers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99067df",
   "metadata": {},
   "source": [
    "# Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb576173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/1044/1*iWQzxhVlvadk6VAJjsgXgg.png\" width=\"600\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/1044/1*iWQzxhVlvadk6VAJjsgXgg.png\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31155a2e",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e81ae",
   "metadata": {},
   "source": [
    "https://keras.io/api/layers/regularization_layers/dropout/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7812d",
   "metadata": {},
   "source": [
    "# Different Types of Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5211c",
   "metadata": {},
   "source": [
    "There are three important types of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbefc76",
   "metadata": {},
   "source": [
    "## Dense/ Fully-Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5b5ffc",
   "metadata": {},
   "source": [
    "Dense layer is the regular deeply connected neural network layer. It is most common and frequently used layer. Dense layer does the below operation on the input and return the output. output = activation(dot(input, kernel) + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cddbd8",
   "metadata": {},
   "source": [
    "## Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d482f7",
   "metadata": {},
   "source": [
    "Convolutional neural networks are neural networks used primarily to classify images (i.e. name what they see), cluster images by similarity (photo search), and perform object recognition within scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaba2d2",
   "metadata": {},
   "source": [
    "## Recurrent Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a0ab9",
   "metadata": {},
   "source": [
    "Recurrent Neural Network(RNN) are a type of Neural Network where the output from previous step are fed as input to the current step. In traditional neural networks, all the inputs and outputs are independent of each other, but in cases like when it is required to predict the next word of a sentence, the previous words are required and hence there is a need to remember the previous words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a134cb",
   "metadata": {},
   "source": [
    "https://keras.io/api/layers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a78f955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
